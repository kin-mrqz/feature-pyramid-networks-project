{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfe5c9e",
   "metadata": {},
   "source": [
    "# FPN Object Detection Visualization\n",
    "\n",
    "This notebook demonstrates the Feature Pyramid Network (FPN) bounding box detection mechanism. We'll load a trained model, perform inference on images, and visualize the detected objects with bounding boxes, class labels, and confidence scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e9f72",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a1828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add modernized_fpn directory to path to import modules\n",
    "sys.path.insert(0, os.path.abspath('modernized_fpn'))\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "from model import Model\n",
    "from backbone.base import Base as BackboneBase\n",
    "from dataset.base import Base as DatasetBase\n",
    "from config.eval_config import EvalConfig as Config\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f0918",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c507f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_PATH = 'modernized_fpn/outputs/checkpoints-20251119144440-voc2007-resnet101-98a73035/model-80000.pth'\n",
    "DATASET_NAME = 'voc2007'\n",
    "BACKBONE_NAME = 'resnet101'\n",
    "\n",
    "# VOC 2007 class names\n",
    "VOC_CLASSES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',\n",
    "    'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "dataset = DatasetBase.from_name(DATASET_NAME)\n",
    "backbone = BackboneBase.from_name(BACKBONE_NAME)(pretrained=False)\n",
    "model = Model(\n",
    "    backbone, \n",
    "    dataset.num_classes(), \n",
    "    pooling_mode=Config.POOLING_MODE,\n",
    "    anchor_ratios=Config.ANCHOR_RATIOS, \n",
    "    anchor_scales=Config.ANCHOR_SCALES,\n",
    "    rpn_pre_nms_top_n=Config.RPN_PRE_NMS_TOP_N, \n",
    "    rpn_post_nms_top_n=Config.RPN_POST_NMS_TOP_N\n",
    ").cuda()\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded from step {checkpoint['step']}\")\n",
    "print(f\"Number of classes: {len(VOC_CLASSES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d12ad",
   "metadata": {},
   "source": [
    "## 3. Define Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, min_side=800, max_side=1333):\n",
    "    \"\"\"Load and preprocess image for the model\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_image = image.copy()\n",
    "    \n",
    "    # Resize image\n",
    "    w, h = image.size\n",
    "    scale = min(min_side / min(h, w), max_side / max(h, w))\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    image = image.resize((new_w, new_h), Image.BILINEAR)\n",
    "    \n",
    "    # Convert to tensor and normalize\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image_tensor = transform(image).cuda()\n",
    "    \n",
    "    return image_tensor, original_image, scale\n",
    "\n",
    "\n",
    "def run_inference(model, image_tensor, confidence_threshold=0.7):\n",
    "    \"\"\"Run model inference and return detections\"\"\"\n",
    "    with torch.no_grad():\n",
    "        forward_input = Model.ForwardInput.Eval(image_tensor)\n",
    "        forward_output = model.eval().forward(forward_input)\n",
    "    \n",
    "    detection_bboxes = forward_output.detection_bboxes\n",
    "    detection_classes = forward_output.detection_classes\n",
    "    detection_probs = forward_output.detection_probs\n",
    "    \n",
    "    # Filter by confidence threshold\n",
    "    mask = detection_probs >= confidence_threshold\n",
    "    detection_bboxes = detection_bboxes[mask]\n",
    "    detection_classes = detection_classes[mask]\n",
    "    detection_probs = detection_probs[mask]\n",
    "    \n",
    "    return detection_bboxes, detection_classes, detection_probs\n",
    "\n",
    "\n",
    "def visualize_detections(image, bboxes, classes, probs, scale, class_names=VOC_CLASSES):\n",
    "    \"\"\"Visualize detections with bounding boxes\"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Color map for different classes\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(class_names)))\n",
    "    \n",
    "    for bbox, cls, prob in zip(bboxes, classes, probs):\n",
    "        # Scale bbox back to original image size\n",
    "        x1, y1, x2, y2 = bbox / scale\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Get class info\n",
    "        class_idx = cls.item()\n",
    "        class_name = class_names[class_idx]\n",
    "        color = colors[class_idx]\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        label = f'{class_name}: {prob:.2f}'\n",
    "        ax.text(\n",
    "            x1, y1 - 5, label,\n",
    "            bbox=dict(facecolor=color, alpha=0.7),\n",
    "            fontsize=10, color='white', weight='bold'\n",
    "        )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def draw_detections_pil(image, bboxes, classes, probs, scale, class_names=VOC_CLASSES):\n",
    "    \"\"\"Draw detections on PIL image for saving\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Try to load a font, fallback to default\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Color map\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(class_names)))\n",
    "    \n",
    "    for bbox, cls, prob in zip(bboxes, classes, probs):\n",
    "        # Scale bbox back to original image size\n",
    "        x1, y1, x2, y2 = bbox / scale\n",
    "        \n",
    "        # Get class info\n",
    "        class_idx = cls.item()\n",
    "        class_name = class_names[class_idx]\n",
    "        color_rgb = tuple((np.array(colors[class_idx][:3]) * 255).astype(int))\n",
    "        \n",
    "        # Draw rectangle\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color_rgb, width=3)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f'{class_name}: {prob:.2f}'\n",
    "        text_bbox = draw.textbbox((x1, y1 - 20), label, font=font)\n",
    "        draw.rectangle(text_bbox, fill=color_rgb)\n",
    "        draw.text((x1, y1 - 20), label, fill='white', font=font)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef21e9",
   "metadata": {},
   "source": [
    "## 4. Run Detection on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your test image path (update this to your actual image path)\n",
    "IMAGE_PATH = 'modernized_fpn/data/VOCdevkit/VOC2007/JPEGImages/000001.jpg'\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "# Process image\n",
    "print(\"Processing image...\")\n",
    "image_tensor, original_image, scale = preprocess_image(IMAGE_PATH)\n",
    "print(f\"Image size: {original_image.size}\")\n",
    "print(f\"Scaled size: {image_tensor.shape}\")\n",
    "\n",
    "# Run inference\n",
    "print(\"Running inference...\")\n",
    "detection_bboxes, detection_classes, detection_probs = run_inference(\n",
    "    model, image_tensor, CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "print(f\"\\nDetections: {len(detection_bboxes)} objects found\")\n",
    "for bbox, cls, prob in zip(detection_bboxes, detection_classes, detection_probs):\n",
    "    print(f\"  - {VOC_CLASSES[cls.item()]}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445c286",
   "metadata": {},
   "source": [
    "## 5. Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detections\n",
    "fig = visualize_detections(\n",
    "    original_image, \n",
    "    detection_bboxes, \n",
    "    detection_classes, \n",
    "    detection_probs, \n",
    "    scale\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88234f75",
   "metadata": {},
   "source": [
    "## 6. Compare Different Confidence Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe806bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different confidence thresholds\n",
    "thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, threshold in enumerate(thresholds):\n",
    "    # Run inference with different thresholds\n",
    "    bboxes, classes, probs = run_inference(model, image_tensor, threshold)\n",
    "    \n",
    "    # Display on subplot\n",
    "    ax = axes[idx]\n",
    "    ax.imshow(original_image)\n",
    "    ax.set_title(f'Confidence â‰¥ {threshold} ({len(bboxes)} detections)', fontsize=14, weight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(VOC_CLASSES)))\n",
    "    \n",
    "    for bbox, cls, prob in zip(bboxes, classes, probs):\n",
    "        x1, y1, x2, y2 = bbox / scale\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        class_idx = cls.item()\n",
    "        color = colors[class_idx]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        label = f'{VOC_CLASSES[class_idx]}: {prob:.2f}'\n",
    "        ax.text(\n",
    "            x1, y1 - 5, label,\n",
    "            bbox=dict(facecolor=color, alpha=0.7),\n",
    "            fontsize=8, color='white', weight='bold'\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2efb1b",
   "metadata": {},
   "source": [
    "## 7. Analyze Detections by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze detections\n",
    "bboxes, classes, probs = run_inference(model, image_tensor, 0.5)\n",
    "\n",
    "# Count detections per class\n",
    "class_counts = {}\n",
    "class_confidences = {}\n",
    "\n",
    "for cls, prob in zip(classes, probs):\n",
    "    class_name = VOC_CLASSES[cls.item()]\n",
    "    if class_name not in class_counts:\n",
    "        class_counts[class_name] = 0\n",
    "        class_confidences[class_name] = []\n",
    "    class_counts[class_name] += 1\n",
    "    class_confidences[class_name].append(prob.item())\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Bar chart of detections per class\n",
    "if class_counts:\n",
    "    classes_list = list(class_counts.keys())\n",
    "    counts_list = list(class_counts.values())\n",
    "    \n",
    "    ax1.bar(range(len(classes_list)), counts_list, color='steelblue')\n",
    "    ax1.set_xticks(range(len(classes_list)))\n",
    "    ax1.set_xticklabels(classes_list, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Number of Detections')\n",
    "    ax1.set_title('Detections per Class', fontsize=14, weight='bold')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Box plot of confidence scores\n",
    "    confidence_data = [class_confidences[c] for c in classes_list]\n",
    "    bp = ax2.boxplot(confidence_data, labels=classes_list, patch_artist=True)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    ax2.set_xticklabels(classes_list, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Confidence Score')\n",
    "    ax2.set_title('Confidence Distribution per Class', fontsize=14, weight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'No detections found', ha='center', va='center', fontsize=14)\n",
    "    ax2.text(0.5, 0.5, 'No detections found', ha='center', va='center', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nDetection Summary:\")\n",
    "print(\"-\" * 50)\n",
    "for class_name, count in class_counts.items():\n",
    "    avg_conf = np.mean(class_confidences[class_name])\n",
    "    print(f\"{class_name:15s}: {count:2d} objects (avg confidence: {avg_conf:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73daf7f5",
   "metadata": {},
   "source": [
    "## 8. Batch Processing Multiple Images\n",
    "\n",
    "Process multiple images from the dataset to showcase the bounding box detection mechanism across various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d855310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get multiple test images\n",
    "image_dir = 'modernized_fpn/data/VOCdevkit/VOC2007/JPEGImages/'\n",
    "image_files = glob.glob(os.path.join(image_dir, '*.jpg'))[:6]  # Process first 6 images\n",
    "\n",
    "# Create grid visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, image_path in enumerate(image_files):\n",
    "    # Process image\n",
    "    image_tensor, original_image, scale = preprocess_image(image_path)\n",
    "    bboxes, classes, probs = run_inference(model, image_tensor, 0.5)\n",
    "    \n",
    "    # Display\n",
    "    ax = axes[idx]\n",
    "    ax.imshow(original_image)\n",
    "    ax.set_title(f'{os.path.basename(image_path)}\\n{len(bboxes)} detections', fontsize=10)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(VOC_CLASSES)))\n",
    "    \n",
    "    for bbox, cls, prob in zip(bboxes, classes, probs):\n",
    "        x1, y1, x2, y2 = bbox / scale\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        class_idx = cls.item()\n",
    "        color = colors[class_idx]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), width, height,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        label = f'{VOC_CLASSES[class_idx]}: {prob:.2f}'\n",
    "        ax.text(\n",
    "            x1, y1 - 3, label,\n",
    "            bbox=dict(facecolor=color, alpha=0.7),\n",
    "            fontsize=7, color='white', weight='bold'\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6a723",
   "metadata": {},
   "source": [
    "## 9. Save Detection Results\n",
    "\n",
    "Save the visualization with bounding boxes to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c046a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save a detection result\n",
    "output_path = 'detection_result.jpg'\n",
    "\n",
    "# Load and process image\n",
    "image_tensor, original_image, scale = preprocess_image(IMAGE_PATH)\n",
    "bboxes, classes, probs = run_inference(model, image_tensor, 0.5)\n",
    "\n",
    "# Draw on PIL image\n",
    "result_image = draw_detections_pil(\n",
    "    original_image.copy(), \n",
    "    bboxes, \n",
    "    classes, \n",
    "    probs, \n",
    "    scale\n",
    ")\n",
    "\n",
    "# Save\n",
    "result_image.save(output_path, quality=95)\n",
    "print(f\"Saved detection result to: {output_path}\")\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.title('Saved Detection Result', fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP3340",
   "language": "python",
   "name": "comp3340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
